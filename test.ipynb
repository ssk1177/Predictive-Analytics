{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2024-05-29T02:55:57.958245Z","iopub.execute_input":"2024-05-29T02:55:57.958827Z","iopub.status.idle":"2024-05-29T02:55:59.954595Z","shell.execute_reply.started":"2024-05-29T02:55:57.958784Z","shell.execute_reply":"2024-05-29T02:55:59.953251Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n\ntarget = df_train[\"Survived\"]     # Target \n\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T02:55:59.955990Z","iopub.execute_input":"2024-05-29T02:55:59.956348Z","iopub.status.idle":"2024-05-29T02:56:00.020842Z","shell.execute_reply.started":"2024-05-29T02:55:59.956317Z","shell.execute_reply":"2024-05-29T02:56:00.019431Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Remark: 'PassengerID' is unique and can be removed","metadata":{}},{"cell_type":"markdown","source":"## Explore data","metadata":{}},{"cell_type":"code","source":"df_train['Cabin'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T02:56:00.022153Z","iopub.execute_input":"2024-05-29T02:56:00.022499Z","iopub.status.idle":"2024-05-29T02:56:00.037368Z","shell.execute_reply.started":"2024-05-29T02:56:00.022468Z","shell.execute_reply":"2024-05-29T02:56:00.036036Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Cabin\nB96 B98        4\nG6             4\nC23 C25 C27    4\nC22 C26        3\nF33            3\n              ..\nE34            1\nC7             1\nC54            1\nE36            1\nC148           1\nName: count, Length: 147, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df_train[[\"Cabin\", \"Survived\"]].groupby(['Cabin']).mean().sort_values(by='Survived', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T03:05:48.347493Z","iopub.execute_input":"2024-05-29T03:05:48.347958Z","iopub.status.idle":"2024-05-29T03:05:48.365985Z","shell.execute_reply.started":"2024-05-29T03:05:48.347920Z","shell.execute_reply":"2024-05-29T03:05:48.364754Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"         Survived\nCabin            \nC62 C64       1.0\nD21           1.0\nD17           1.0\nD19           1.0\nC148          1.0\n...           ...\nC46           0.0\nC30           0.0\nC128          0.0\nC124          0.0\nT             0.0\n\n[147 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n    </tr>\n    <tr>\n      <th>Cabin</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>C62 C64</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>D21</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>D17</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>D19</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>C148</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>C46</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>C30</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>C128</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>C124</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>T</th>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>147 rows Ã— 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(df_train.isnull().sum() / len(df_train) * 100)\n\n# Drop unwanted columns -  Need to revisit this step\ndf_train = df_train.drop([\"Ticket\", \"Cabin\", \"PassengerId\", \"Survived\"], axis = 1)\ndf_test = df_test.drop([\"Ticket\", \"Cabin\", \"PassengerId\"], axis = 1)\n\n## Reasoning\n#1. Features such as PassengerId and Name will be unique, so no point in keeping these in training data.\n#2. ","metadata":{"execution":{"iopub.status.busy":"2024-05-29T02:56:00.838521Z","iopub.status.idle":"2024-05-29T02:56:00.838941Z","shell.execute_reply.started":"2024-05-29T02:56:00.838742Z","shell.execute_reply":"2024-05-29T02:56:00.838760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()\n\ndef df_clean(dataframe):\n    # Convert categorical to numerical\n    dataframe[\"Sex\"] = le.fit_transform(dataframe[\"Sex\"])\n    dataframe[\"Embarked\"] = le.fit_transform(dataframe[\"Embarked\"])\n\n    # Fill null/missing values\n    dataframe[\"Age\"] = dataframe[\"Age\"].fillna(dataframe[\"Age\"].mean())\n    dataframe[\"Embarked\"] = dataframe[\"Embarked\"].fillna(dataframe[\"Embarked\"].mean())\n    dataframe[\"Fare\"] = dataframe[\"Fare\"].fillna(dataframe[\"Fare\"].mean())\n\n    return dataframe\n\ndf_train = df_clean(df_train)\ndf_test = df_clean(df_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T02:56:00.840732Z","iopub.status.idle":"2024-05-29T02:56:00.841186Z","shell.execute_reply.started":"2024-05-29T02:56:00.840945Z","shell.execute_reply":"2024-05-29T02:56:00.840987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observation:\n- Scaling is required for features such as Age and fare","metadata":{}},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"# Combining 'parch' and 'sibsp' to create new feature named as 'family_size'\n\ndef feat_engg(dataframe):\n    dataframe['family_size'] = dataframe['Parch'] + dataframe['SibSp']\n    dataframe.drop(['Parch', 'SibSp'], axis=1, inplace=True)\n\n    # Create a derived feature called 'is_alone' using the family_size feature\n    dataframe['is_alone'] = 1\n    #dataframe['is_alone'].loc[dataframe['family_size'] > 1] = 0\n    dataframe.loc[dataframe['family_size'] > 1, 'is_alone'] = 0\n    \n    # Create new feature\n    dataframe['title'] =  dataframe['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n\n    # Remove the 'name' feature\n    dataframe.drop([\"Name\"], axis=1, inplace=True)\n\n    # Mark the 'title' as 'rare' if the value is less than 10\n    rare_titles = (dataframe['title'].value_counts() < 10)\n    rare_titles\n\n    dataframe.loc[dataframe.title == 'Miss', 'title'] = 'Mrs'\n    dataframe['title'] = dataframe.title.apply(lambda x: 'rare' if rare_titles[x] else x)\n\n    dataframe[\"title\"] = le.fit_transform(dataframe[\"title\"])\n    #dataframe[\"title\"] = dataframe[\"title\"].replace(['Mr', 'Mrs', 'Master', 'rare'], [0, 1, 2, 3])\n    # Print the head to verify the data\n    dataframe.head()\n    \n    return dataframe","metadata":{"execution":{"iopub.status.busy":"2024-05-29T02:56:00.842752Z","iopub.status.idle":"2024-05-29T02:56:00.843189Z","shell.execute_reply.started":"2024-05-29T02:56:00.842952Z","shell.execute_reply":"2024-05-29T02:56:00.842996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = feat_engg(df_train)\ndf_test = feat_engg(df_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T02:56:00.844563Z","iopub.status.idle":"2024-05-29T02:56:00.844955Z","shell.execute_reply.started":"2024-05-29T02:56:00.844761Z","shell.execute_reply":"2024-05-29T02:56:00.844778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Create an instance of the scaler\n# scaler = StandardScaler()\n\n# # Fit on training data\n# scaler.fit(df_train)\n\n# # Transform both training and test data\n# X_train_scaled = scaler.transform(df_train)\n# X_test_scaled = scaler.transform(df_test)\n\n\n# df_train = pd.DataFrame(X_train_scaled, columns=df_train.columns)\n# df_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T02:56:00.846657Z","iopub.status.idle":"2024-05-29T02:56:00.847054Z","shell.execute_reply.started":"2024-05-29T02:56:00.846839Z","shell.execute_reply":"2024-05-29T02:56:00.846854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import tree\n\n#x_train, x_test, y_train, y_test = train_test_split(df_train, target, test_size=0.2, random_state=117)\n\nclf = tree.DecisionTreeClassifier()\n\n#clf.fit(x_train, y_train)\n\n#clf.fit(df_train, target)\n\n# Define the parameter grid to tune the hyperparameters\nparam_grid = {\n    'criterion': ['gini', 'entropy'],\n    'max_depth': [2,4,6,8,10,12, 20, 30, None],\n    'min_samples_split': np.arange(2, 10, 1),\n    'min_samples_leaf': np.arange(1, 10, 1),\n    'splitter':[\"best\",\"random\"]\n}\n\nclf_dt = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring = 'accuracy')\nclf_dt.fit(df_train, target)\n\nbest_dtree_reg = clf_dt.best_estimator_ # Get the best estimator from the grid search\n\ny_pred = best_dtree_reg.predict(df_test)\n\nprint('Best Criterion:', clf_dt.best_estimator_.get_params()['criterion'])\nprint('Max depth:', clf_dt.best_estimator_.get_params()['max_depth'])\nprint('Min Samples split:', clf_dt.best_estimator_.get_params()['min_samples_split'])\nprint('Min Samples Leaf:', clf_dt.best_estimator_.get_params()['min_samples_leaf'])\nprint('Best Splitter:', clf_dt.best_estimator_.get_params()['splitter'])\n\nprint(f\"\\nBest score:\", clf_dt.best_score_)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T02:56:00.848283Z","iopub.status.idle":"2024-05-29T02:56:00.848803Z","shell.execute_reply.started":"2024-05-29T02:56:00.848532Z","shell.execute_reply":"2024-05-29T02:56:00.848553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Retrain with best hyper-parameters\nclf = tree.DecisionTreeClassifier(\n    criterion= clf_dt.best_estimator_.get_params()['criterion'],\n    max_depth= clf_dt.best_estimator_.get_params()['max_depth'],\n    min_samples_split= clf_dt.best_estimator_.get_params()['min_samples_split'],\n    min_samples_leaf= clf_dt.best_estimator_.get_params()['min_samples_leaf'],\n    splitter= clf_dt.best_estimator_.get_params()['splitter'])\nclf.fit(df_train, target)\npred = clf.predict(df_test)\nprint(pred)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T02:56:00.850829Z","iopub.status.idle":"2024-05-29T02:56:00.851330Z","shell.execute_reply.started":"2024-05-29T02:56:00.851074Z","shell.execute_reply":"2024-05-29T02:56:00.851096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Eperiment to improve accuracy\n# Method: tree Pruning\n# Compute the cost-complexity pruning path\n\nclf_rf = RandomForestClassifier(n_estimators=100)\nclf_rf.fit(df_train, target)\n\npred = clf_rf.predict(df_test)\n# print(\"score:\", accuracy_score(y_test, pred))\n\n\n#clf_rf.fit(feats, target)\n#pred = clf_rf.predict(df_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T02:56:00.852604Z","iopub.status.idle":"2024-05-29T02:56:00.853132Z","shell.execute_reply.started":"2024-05-29T02:56:00.852837Z","shell.execute_reply":"2024-05-29T02:56:00.852859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(\"feats:\", feats.columns)\n# print(\"test feats:\",df_test.columns)\n\n# #df_test.isnull().sum()\n\n# pred = clf.predict(x_test)\n# score = accuracy_score(y_test, pred)\n# #pred = clf.predict(df_test)\n# #print(\"predictions\", pred)\n# print(\"score:\", score)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T02:56:00.854914Z","iopub.status.idle":"2024-05-29T02:56:00.855463Z","shell.execute_reply.started":"2024-05-29T02:56:00.855197Z","shell.execute_reply":"2024-05-29T02:56:00.855218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_subm = pd.read_csv(\"/kaggle/input/titanic/gender_submission.csv\")\ny = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ndf_subm.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T02:56:00.856781Z","iopub.status.idle":"2024-05-29T02:56:00.857295Z","shell.execute_reply.started":"2024-05-29T02:56:00.857034Z","shell.execute_reply":"2024-05-29T02:56:00.857056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\"PassengerId\": y[\"PassengerId\"],\n       \"Survived\": pred})\nsubmission.head()\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T02:56:00.859051Z","iopub.status.idle":"2024-05-29T02:56:00.859555Z","shell.execute_reply.started":"2024-05-29T02:56:00.859289Z","shell.execute_reply":"2024-05-29T02:56:00.859310Z"},"trusted":true},"execution_count":null,"outputs":[]}]}